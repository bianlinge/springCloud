server.ip=127.0.0.1
server.port=80
spring.application.name=app-service-web
destdir=E:\\test\\destdir\\

### activemq
# tcp://localhost:61616
#spring.activemq.broker-url=tcp://127.0.0.1:61616
##true 表示使用内置的MQ，false则连接服务器
#spring.activemq.in-memory=false
##true表示使用连接池；false时，每发送一条数据创建一个连接
#spring.activemq.pool.enabled=true
##连接池最大连接数
#spring.activemq.pool.max-connections=10
##空闲的连接过期时间，默认为30秒
#spring.activemq.pool.idle-timeout=30000
#强制的连接过期时间，与idleTimeout的区别在于：idleTimeout是在连接空闲一段时间失效，而expiryTimeout不管当前连接的情况，只要达到指定时间就失效。默认为0，never

#============== eureka ===================
#eureka.instance.hostname=${server.ip}
#eureka.client.service-url.defaultZone=http://127.0.0.1:8761/eureka/
#eureka.instance.prefer-ip-address=true
#ribbon.eureka.enabled=false


#===================  elasticsearch  ===================
#spring.data.elasticsearch.cluster-name=elasticsearch-cluster
#spring.data.elasticsearch.cluster-nodes=127.0.0.1:9200

#============== kafka ===================
# 指定kafka 代理地址，可以多个
#spring.kafka.bootstrap-servers=192.168.111.132:9092

#=============== kafka-provider  ==================

#spring.kafka.producer.retries=0
## 每次批量发送消息的数量
#spring.kafka.producer.batch-size=16384
#spring.kafka.producer.buffer-memory=33554432
#
## 指定消息key和消息体的编解码方式
#spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

#=============== kafka-consumer  =======================
# 指定默认消费者group id
#spring.kafka.consumer.group-id=test-hello-group
#
#spring.kafka.consumer.auto-offset-reset=earliest
#spring.kafka.consumer.enable-auto-commit=true
#spring.kafka.consumer.auto-commit-interval=100
#
## 指定消息key和消息体的编解码方式
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#
